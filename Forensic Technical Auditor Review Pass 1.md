# Pass 1 — Capability Map

| Capability | Demo intent (1 sentence) | Observable implementation | Maturity | Key gaps |
|---|---|---|---|---|
| **Business-Aware Topology Graph** | Models the telco as a graph with nodes sized/colored by financial throughput and SLA tier. | [topology.py](file:///Users/himanshu/Projects/Pedkai/backend/app/api/topology.py): [get_topology_graph()](file:///Users/himanshu/Projects/Pedkai/backend/app/api/topology.py#57-126), [get_entity()](file:///Users/himanshu/Projects/Pedkai/backend/app/api/topology.py#128-169), [get_impact_tree()](file:///Users/himanshu/Projects/Pedkai/backend/app/api/topology.py#171-223) with recursive neighbour traversal; [EntityRelationshipORM](file:///Users/himanshu/Projects/Pedkai/backend/app/models/topology_models.py); [TopologySchemas](file:///Users/himanshu/Projects/Pedkai/backend/app/schemas/topology.py). | Partial | • `network_entities` table dropped; topology stores only relationships, not entity metadata (type, revenue, geo). • No revenue-weighted node scoring observable in backend. |
| **Alarm-to-Incident Correlation & Clustering** | Reduces 47+ raw alarms into 3 actionable clusters using topology proximity, temporal window, and symptom similarity. | [AlarmCorrelationService](file:///Users/himanshu/Projects/Pedkai/backend/app/services/alarm_correlation.py): [correlate_alarms()](file:///Users/himanshu/Projects/Pedkai/backend/app/services/alarm_correlation.py#39-115) (3 strategies), [calculate_noise_reduction()](file:///Users/himanshu/Projects/Pedkai/backend/app/services/alarm_correlation.py#116-125), [get_customer_impact()](file:///Users/himanshu/Projects/Pedkai/backend/app/services/alarm_correlation.py#126-156); [service_impact.py](file:///Users/himanshu/Projects/Pedkai/backend/app/api/service_impact.py): `/clusters`, `/noise-wall` endpoints. | Partial | • H-8: `/clusters` queries `decision_traces` table instead of actual alarms — clusters synthetic, not real alarm data. • No real-time ingestion pipeline from OSS/NMS. |
| **Graph-Based Root Cause Analysis** | Traces through multi-layer topology (physical → logical → service → customer) to identify root cause entity. | [topology.py](file:///Users/himanshu/Projects/Pedkai/backend/app/api/topology.py): [get_impact_tree()](file:///Users/himanshu/Projects/Pedkai/backend/app/api/topology.py#171-223) with [get_neighbours_recursive()](file:///Users/himanshu/Projects/Pedkai/backend/app/api/topology.py#184-211) (BFS, max 5 hops); [cx_intelligence.py](file:///Users/himanshu/Projects/Pedkai/backend/app/services/cx_intelligence.py): recursive CTE with depth/row limit; [service_impact.py](file:///Users/himanshu/Projects/Pedkai/backend/app/api/service_impact.py): [get_cluster_deep_dive()](file:///Users/himanshu/Projects/Pedkai/backend/app/api/service_impact.py#213-262). | Partial | • No actual anomaly detection engine to trigger RCA automatically. • Deep-dive reasoning chain is LLM-generated, not graph-derived. |
| **Decision Memory (Semantic Similarity Search)** | Finds past incidents with 0.92+ cosine similarity using pgvector, enabling "remember and reuse" resolution patterns. | [DecisionTraceRepository](file:///Users/himanshu/Projects/Pedkai/backend/app/services/decision_repository.py): [find_similar()](file:///Users/himanshu/Projects/Pedkai/backend/app/services/decision_repository.py#126-177) with pgvector cosine distance, feedback-score boosting, threshold gating; [EmbeddingService](file:///Users/himanshu/Projects/Pedkai/backend/app/services/embedding_service.py): Gemini `text-embedding-004`; [record_feedback()](file:///Users/himanshu/Projects/Pedkai/backend/app/services/decision_repository.py#178-222) with junction table; [get_reasoning_chain()](file:///Users/himanshu/Projects/Pedkai/backend/app/services/decision_repository.py#242-277) recursive CTE. | Partial | • Requires `GEMINI_API_KEY` — no on-prem embedding fallback. • No observable bulk-embedding pipeline to backfill existing decisions. |
| **Incident Lifecycle with Human Gates** | 7-act lifecycle (Anomaly → Detection → RCA → SITREP → Resolution → Learning) with 3 mandatory human approval gates. | [incidents.py](file:///Users/himanshu/Projects/Pedkai/backend/app/api/incidents.py): [create_incident()](file:///Users/himanshu/Projects/Pedkai/backend/app/api/incidents.py#65-106), [advance_lifecycle()](file:///Users/himanshu/Projects/Pedkai/backend/app/api/incidents.py#190-221), [approve_sitrep()](file:///Users/himanshu/Projects/Pedkai/backend/app/api/incidents.py#223-245), [approve_action()](file:///Users/himanshu/Projects/Pedkai/backend/app/api/incidents.py#260-282), [close_incident()](file:///Users/himanshu/Projects/Pedkai/backend/app/api/incidents.py#271-293), [get_audit_trail()](file:///Users/himanshu/Projects/Pedkai/backend/app/api/incidents.py#324-350); [IncidentORM](file:///Users/himanshu/Projects/Pedkai/backend/app/models/incident_orm.py) with approval fields and timestamps. | Partial | • No automated anomaly-to-incident creation pipeline; incidents must be created via API call. • Frontend lifecycle view is basic ([page.tsx](file:///Users/himanshu/Projects/Pedkai/frontend/app/page.tsx) monolith). |
| **AI SITREP Generation** | LLM synthesises RCA results, decision memory matches, and causal evidence into an actionable natural-language briefing. | [LLMService](file:///Users/himanshu/Projects/Pedkai/backend/app/services/llm_service.py): [generate_sitrep()](file:///Users/himanshu/Projects/Pedkai/backend/app/api/incidents.py#142-188) with structured prompt, PII scrubbing, confidence scoring, cost estimation, AI watermark, model version tracking; [LLMAdapter](file:///Users/himanshu/Projects/Pedkai/backend/app/services/llm_adapter.py): async Gemini + on-prem adapter; [SitrepPanel.tsx](file:///Users/himanshu/Projects/Pedkai/frontend/app/components/SitrepPanel.tsx): renders watermark banner. | Partial | • Confidence scoring uses heuristic formula (memory hits + evidence count), not calibrated model. • Template fallback for low-confidence outputs is static text. |
| **Sleeping Cell Detection** | Detects "silent failures" (zero users, no alarms, NMS green) invisible to legacy monitoring, using absence-of-signal Z-score analysis. | Not observable. | Absent | • No backend service, anomaly detector, or KPI threshold engine exists. • Demo depicts Z-score (−6.8σ) analysis and BBU restart remediation — none implemented. |
| **Revenue / SLA Impact Quantification** | Calculates revenue-at-risk per incident cluster and predicts SLA breach countdown timers. | [AutonomousShieldService](file:///Users/himanshu/Projects/Pedkai/backend/app/services/autonomous_shield.py): [calculate_value_protected()](file:///Users/himanshu/Projects/Pedkai/backend/app/services/autonomous_shield.py#156-184) with counterfactual methodology and confidence intervals; [bss_adapter.py](file:///Users/himanshu/Projects/Pedkai/backend/app/services/bss_service.py) / [BillingAccountORM](file:///Users/himanshu/Projects/Pedkai/backend/app/models/bss_orm.py); [service_impact.py](file:///Users/himanshu/Projects/Pedkai/backend/app/api/service_impact.py): [get_impacted_customers()](file:///Users/himanshu/Projects/Pedkai/backend/app/api/service_impact.py#28-91) with revenue-at-risk. | Prototype | • N-4: Uses policy parameters as revenue proxies, not actual BSS billing data. • SLA breach countdown timer shown in demos not implemented. |
| **Proactive Customer Communications** | Contacts at-risk customers proactively via SMS/email before they notice degradation, with GDPR opt-in enforcement. | [ProactiveCommsService](file:///Users/himanshu/Projects/Pedkai/backend/app/services/proactive_comms.py): [draft_communication()](file:///Users/himanshu/Projects/Pedkai/backend/app/services/proactive_comms.py#74-122), consent check via `CustomerORM.consent_proactive_comms`; [cx_intelligence.py](file:///Users/himanshu/Projects/Pedkai/backend/app/services/cx_intelligence.py): [trigger_proactive_care()](file:///Users/himanshu/Projects/Pedkai/backend/app/services/cx_intelligence.py#107-126). | Prototype | • N-5: [trigger_proactive_care](file:///Users/himanshu/Projects/Pedkai/backend/app/services/cx_intelligence.py#107-126) bypasses consent checks. • Channel is `simulation` only — no real SMS/email integration. |
| **Causal AI Engine** | Demonstrates Granger causality analysis to prove statistical causation (not just correlation) between network events. | [llm_service.py](file:///Users/himanshu/Projects/Pedkai/backend/app/services/llm_service.py): accepts `causal_evidence` parameter and formats Granger-causes strings into SITREP prompt; referenced in confidence scoring. No engine computes this evidence. | Absent | • No Granger causality computation, time-series analysis, or statsmodels integration observable. • Demo shows p-values and lag periods that have no backend source. |
| **Autonomous Business Shield (Predictive Drift)** | Detects KPI drift pre-breach, predicts disruption time, and generates preventive change requests — "intercepting" incidents before customer impact. | [AutonomousShieldService](file:///Users/himanshu/Projects/Pedkai/backend/app/services/autonomous_shield.py): [detect_drift()](file:///Users/himanshu/Projects/Pedkai/backend/app/services/autonomous_shield.py#45-84) with linear extrapolation, [evaluate_preventive_action()](file:///Users/himanshu/Projects/Pedkai/backend/app/services/autonomous_shield.py#85-126), [generate_change_request()](file:///Users/himanshu/Projects/Pedkai/backend/app/services/autonomous_shield.py#127-155); [autonomous.py](file:///Users/himanshu/Projects/Pedkai/backend/app/api/autonomous.py): `/scorecard`, `/drift-detect`, `/change-request` endpoints; [PolicyEngine](file:///Users/himanshu/Projects/Pedkai/backend/app/services/policy_engine.py): YAML-driven policy evaluation with safe-eval. | Prototype | • No real KPI ingestion pipeline — drift detection requires manual API call with current/baseline values. • Demo shows autonomous execution (revert policy via Netconf); code explicitly prohibits autonomous action. |
| **NOC Dashboard (Real-Time Operations View)** | Unified NOC dashboard with live alarm feed, topology visualisation, incident lifecycle, and AI scorecard. | [page.tsx](file:///Users/himanshu/Projects/Pedkai/frontend/app/page.tsx): main dashboard; [SSE endpoint](file:///Users/himanshu/Projects/Pedkai/backend/app/api/sse.py): `/api/v1/stream/alarms`; extracted components: [StatCard.tsx](file:///Users/himanshu/Projects/Pedkai/frontend/app/components/StatCard.tsx), [AlarmCard.tsx](file:///Users/himanshu/Projects/Pedkai/frontend/app/components/AlarmCard.tsx), [SitrepPanel.tsx](file:///Users/himanshu/Projects/Pedkai/frontend/app/components/SitrepPanel.tsx). | Prototype | • M-1: Frontend remains a monolith ([page.tsx](file:///Users/himanshu/Projects/Pedkai/frontend/app/page.tsx) > 500 lines). • N-2: SSE generator holds DB sessions indefinitely. |
